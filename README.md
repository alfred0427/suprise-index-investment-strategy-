#  Surprise Index Investment Strategy


## ä¸€ã€ç­–ç•¥ä»‹ç´¹
åœ¨é€™æ¬¡ç ”ç©¶ä¸­ï¼Œæˆ‘å€‘ç™¼ç¾è²¡å‹™å ±è¡¨é©šå¥‡ç¨‹åº¦å°æ–¼å€‹è‚¡è¶…é¡å ±é…¬çš„éå»¶æ€§ï¼Œä¸¦ç”¨æ­¤ç‰¹æ€§è¡ç”Ÿå‡ºä¸€å€‹é‡åŒ–å› å­æŠ•è³‡ç­–ç•¥ã€‚é‹ç”¨å¤šå…ƒå›æ­¸ã€éš¨æ©Ÿæ£®æ—æ¨¡å‹ä¾†å‹•æ…‹æ­é…æ¯ä¸€å­£æ‰€æŒæœ‰è‚¡ç¥¨å¤šç©ºçµ„åˆï¼Œä¸¦åœ¨è¨“ç·´æœŸè·Ÿæ¸¬è©¦æœŸéƒ½ç²å¾—å„ªæ–¼å¸‚å ´çš„å ±é…¬ã€‚
This is a quantitative investment strategy driven by the surpriseness of company's key financial index, using both linear and machine learning model to build an risk neutral stock seletion strategy

ä»¥ä¸‹æ˜¯ç­–ç•¥é—œéµè®Šæ•¸çš„è¡¡é‡æ–¹æ³•:
åƒè€ƒ _Piotroski F-score_ï¼Œæˆ‘å€‘å°‡è²¡å ±çš„é©šå¥‡ç¨‹åº¦ç”¨å…­å€‹é—œéµè²¡å‹™æŒ‡æ¨™ä¾†è¡¡é‡ï¼Œåˆ†åˆ¥æ˜¯ç¨…å‰ROAã€EPSã€Gross profitã€Operatiin Cash flowã€current ratio.

ä¸¦ä¸”åˆ†åˆ¥é€²è¡Œä»¥ä¸‹è¨ˆç®—è½‰æ›ç‚ºé©šå¥‡æŒ‡æ•¸:   
   - _é©šå¥‡æŒ‡æ•¸ = æœ¬å­£èˆ‡å»å¹´åº¦åŒå­£è²¡å‹™æŒ‡æ¨™è®ŠåŒ–é‡ âˆ’ ä¸Šå­£è²¡å ±å…¬å¸ƒæ—¥å¾Œä¸€å¤©â¾„è²¡å ±â½‡å‰ä¸€å¤©çš„è‚¡åƒ¹å ±é…¬ç‡_

åœ¨è¨ˆç®—å‡ºäº”å€‹è²¡å‹™æŒ‡æ¨™çš„é©šå¥‡æŒ‡æ¨™å¾Œï¼Œæˆ‘å€‘å°‡ç”¨**å¤šå…ƒå›æ­¸æ¨¡å‹**å’Œ**éš¨æ©Ÿæ£®æ—æ¨¡å‹**ä¾†çµ¦äºˆè©²å­£è²¡å ±é©šå¥‡åˆ†æ•¸ã€‚

## äºŒã€è³‡æ–™å‰è™•ç†

### å‡½å¼åº«
````python
import yfinance as yf
import statsmodels.api as sm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from scipy.stats import pearsonr
from tqdm import tqdm 
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
````
### ç‰©ä»¶å°å‘ç¨‹å¼è¨­è¨ˆï¼šé©šå¥‡æŒ‡æ¨™è¨ˆç®—class

é€™å€‹ SurpriseAnalyzer é¡åˆ¥æ˜¯ä¸€å€‹é‡å°å°ç£è‚¡ç¥¨é€²è¡Œè²¡å ±ã€Œé©šå¥‡æŒ‡æ¨™åˆ†æã€çš„å·¥å…·ã€‚çµ¦å®šä¸€å®¶å…¬å¸åç¨±ï¼Œå®ƒæœƒè‡ªå‹•è®€å–ç›¸é—œè²¡å ±æ•¸æ“šï¼ˆå¦‚ EPSã€æ¯›åˆ©ç‡ã€ROA ç­‰ï¼‰èˆ‡è‚¡åƒ¹ï¼Œè¨ˆç®—è²¡å ±å…¬å¸ƒå‰å¾Œçš„å­£å ±é…¬ï¼Œä¸¦æ¨™æº–åŒ–å„æŒ‡æ¨™è®Šå‹•ï¼Œé€²ä¸€æ­¥æ¨ç®—æ¯å­£çš„ã€Œé©šå¥‡æŒ‡æ¨™ã€â”€â”€å³è²¡å ±è¡¨ç¾èˆ‡å¸‚å ´é æœŸè½å·®ã€‚
````python

class SurpriseAnalyzer:
    def __init__(self, stock_name):
        """
        åˆå§‹åŒ–åˆ†æå™¨ï¼Œè¨­å®šå…¬å¸åç¨±ï¼Œè®€å–åŸºç¤è³‡æ–™
        """
        self.stock_name = stock_name
        self._stock_code = None
        self._market_index = None
        self._price_data = None
        self.df = None  # å„²å­˜æœ€çµ‚åŒ…å«é©šå¥‡æŒ‡æ¨™çš„ DataFrame
        self._load_stock_code()
        self._load_price_data()
        self._cal_this_next_season_return()
    
    def __repr__(self):
        """
        é¡¯ç¤ºåˆ†æç‰©ä»¶çš„åŸºæœ¬è³‡è¨Šèˆ‡ç‹€æ…‹
        """
        return (f"EPSAnalyzer(stock_name='{self.stock_name}', "
                f"stock_code='{self._stock_code}', "
                f"rows={len(self.df) if self.df is not None else 0}, "
                f"columns={len(self.df.columns) if self.df is not None else 0})")

    def _get_stock_code(self):
        """
        æ ¹æ“šè‚¡ç¥¨åç¨±ï¼Œå¾ EPS æª”ä¸­å–å¾—è‚¡ç¥¨ä»£è™Ÿä¸¦åŠ ä¸Š '.TW'ã€‚
        """
        df = pd.read_csv("C:/Users/USER/Downloads/2010è‡³ä»Šeps.csv")
        stock_code = df[df["åç¨±"] == self._stock_name]["ä»£è™Ÿ"]
        return str(stock_code.values[0]) + '.TW'

    def _download_market_data(self):
        """
        ä½¿ç”¨ yfinance ä¸‹è¼‰æŒ‡å®šè‚¡ç¥¨çš„æ¯æ—¥è‚¡åƒ¹è³‡æ–™ã€‚
        """
        return yf.download(tickers=self._stock_code, interval="1d")

    def _load_financial_data(self):
        """
        è¼‰å…¥æ‰€æœ‰è²¡å ±æŒ‡æ¨™è³‡æ–™ï¼ŒåŒ…æ‹¬ EPSã€æµå‹•æ¯”ç‡ç­‰ã€‚
        """
        return {
            'eps': pd.read_csv("data/2010è‡³ä»Šeps.csv"),
            'current_ratio': pd.read_csv("data/curren_ratio.csv"),
            'gross_profit': pd.read_csv("data/gross_profit.csv"),
            'operating_cashflow': pd.read_csv("data/operating_cashflow.csv"),
            'roa_beforetta': pd.read_csv("data/roa_beforetta.csv")
        }

    def _load_report_dates(self):
        """
        è¼‰å…¥è²¡å ±å…¬å¸ƒæ—¥æœŸè³‡æ–™ã€‚
        """
        return pd.read_csv("C:/Users/USER/Downloads/è²¡å ±å…¬å¸ƒæ—¥.csv")

    def _extract_time_series(self, df, name):
        """
        å¾æŒ‡å®šè³‡æ–™æ¡†ä¸­æŠ½å‡ºè©²è‚¡ç¥¨çš„æ™‚é–“åºåˆ—è³‡æ–™ï¼Œä¸¦è½‰ç‚º datetime indexã€‚
        """
        ts = df[df["åç¨±"] == self._stock_name].T.iloc[2:].sort_index()
        ts.columns = [name]
        ts.index = pd.DatetimeIndex(ts.index)
        return ts

    def _cal_this_next_season_return(self):
        """
        æ•´åˆæ‰€æœ‰è²¡å ±æŒ‡æ¨™èˆ‡è²¡å ±å…¬å¸ƒæ—¥ï¼Œå»ºç«‹ä¸»åˆ†æè³‡æ–™æ¡† dfã€‚
        åŒ…æ‹¬è¨ˆç®—è²¡å ±å…¬å¸ƒæ—¥å‰ä¸€å­£å ±é…¬èˆ‡è²¡å ±å¾Œå ±é…¬ã€‚
        """
        df = self._extract_time_series(self._financial_data['eps'], "eps")
        df["current_ratio"] = self._extract_time_series(self._financial_data['current_ratio'], "current_ratio")
        df["gross_profit"] = self._extract_time_series(self._financial_data['gross_profit'], "gross_profit")
        df["operating_cashflow"] = self._extract_time_series(self._financial_data['operating_cashflow'], "operating_cashflow")
        df["roa_beforetta"] = self._extract_time_series(self._financial_data['roa_beforetta'], "roa_beforetta")

        date = self._report_dates[self._report_dates["åç¨±"] == self._stock_name].T.iloc[2:].sort_index()
        df["date"] = pd.DatetimeIndex(date.iloc[:, 0])

        df["past_season_return"] = np.nan
        df["observed_period"] = None
        df["this_season_return"] = np.nan

        for i in range(1, len(df) - 1):
            start_date = df.iloc[i - 1]["date"] + pd.Timedelta("1d")
            end_date = df.iloc[i]["date"]

            price_series = pd.to_numeric(self._market_index, errors='coerce')
            past_period = price_series.loc[start_date:end_date].dropna()

            if not past_period.empty:
                returns = (past_period.iloc[-1] - past_period.iloc[0]) / past_period.iloc[0]
                this_date = df.iloc[i]["date"]
                next_date = df.iloc[i + 1]["date"]
                observed_period = self._market_data.loc[this_date:next_date].dropna()

                date_index = df.index[i]
                df.at[date_index, "past_season_return"] = returns
                df.at[date_index, "observed_period"] = observed_period

                if isinstance(observed_period, pd.DataFrame) and len(observed_period) > 2:
                    df.at[date_index, "this_season_return"] = (observed_period["Close"].iloc[-1] - observed_period["Open"].iloc[0]) / observed_period["Open"].iloc[0]
                else:
                    df.at[date_index, "this_season_return"] = np.nan

        return df

    def _calculate_surprise_index(self, df, indicator):
        df = df.copy()
        df["growth"] = df[indicator].pct_change()
        df["month"] = df.index.month
        df["seasonal_gfgrowth"] = df.groupby("month")["growth"].diff()
        df["seasonal_growth"] = df.groupby("month")[indicator].diff()
        df["seasonal_perform_index"] = df["seasonal_growth"]

        df["standardized_past_season_return"] = (df["past_season_return"] - np.mean(df["past_season_return"])) / np.std(df["past_season_return"])
        df["standardized_perform_index"] = (df["seasonal_perform_index"] - np.mean(df["seasonal_perform_index"])) / np.std(df["seasonal_perform_index"])
        df["standardized_growth"] = (df["growth"] - np.mean(df["growth"])) / np.std(df["growth"])

        surprised_index = df["standardized_perform_index"] - df["standardized_past_season_return"]
        return surprised_index

    def _analyze(self):
        self.df["surprised_index_eps"] = self._calculate_surprise_index(self.df, "eps")
        self.df["surprised_index_current_ratio"] = self._calculate_surprise_index(self.df, "current_ratio")
        self.df["surprised_index_operating_cashflow"] = self._calculate_surprise_index(self.df, "operating_cashflow")
        self.df["surprised_index_gross_profit"] = self._calculate_surprise_index(self.df, "gross_profit")
        self.df["surprised_index_roa_beforetta"] = self._calculate_surprise_index(self.df, "roa_beforetta")
        return self.df
    

````
### ç‰©ä»¶è¼¸å‡ºç¯„ä¾‹ï¼šä»¥å°æ³¥ç‚ºä¾‹
å¦‚æœæˆ‘å€‘åœ¨è¼¸å…¥å°æ³¥ï¼ŒSurpriseAnalyzeræœƒæ ¹æ“šä¸Šè¿°é‚è¼¯è¨ˆç®—å‡ºå°æ³¥ 2011-Q3 åˆ° 2024-Q3 æ¯ä¸€å­£çš„äº”å€‹é©šå¥‡æŒ‡æ¨™ (æœ¬ç ”ç©¶ç‰¹å¾µè®Šæ•¸)ã€å’Œä¸‹å­£è‚¡åƒ¹å ±é…¬ç‡(ç›®æ¨™è®Šæ•¸)ï¼Œä¸¦å›å‚³ä¸€å€‹ä»¥è²¡å ±å…¬å¸ƒæ¬¡æ•¸ç‚ºæ¨£æœ¬æ•¸çš„dataframeã€‚é€™æ¨£åšçš„å¥½è™•æ˜¯å¯ä»¥å…ˆå¿½è¦–æ¯å®¶ä¸Šå¸‚æ«ƒå…¬å¸çš„ç•°è³ªæ€§ï¼Œæ–¹ä¾¿åšçµ±è¨ˆæª¢é©—ã€‚
å…¶ä»–é¡åˆ¥è®Šæ•¸åŒ…å«ï¼šå…¬å¸åç¨±ã€ç”¢æ¥­åˆ¥ã€å­ç”¢æ¥­åˆ¥ï¼Œæ–¹ä¾¿æ—¥å¾Œå­æ¨£æœ¬å›æ­¸å’Œå›æ¸¬ä½¿ç”¨ã€‚
````python
analyzer = SurpriseAnalyzer("å°æ³¥")
result = analyzer.analyze()
````
| index | stock | date       | industry | sub_industry | past_season_return | this_season_return | capital         | surprised_index_eps | surprised_index_gross_profit | surprised_index_roa_beforetta | surprised_index_operating_cashflow | surprised_index_current_ratio | observed_period     |
|-------|-------|------------|----------|---------------|--------------------|---------------------|------------------|----------------------|-------------------------------|-------------------------------|-------------------------------|----------------------------|----------------------|
| 306   | å°æ³¥  | 2011-11-08 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | -0.051613          | -0.083555           | 77,511,817,420   | 0.607769             | 0.760453                      | 0.426872                      | 1.46689                      | 0.25609                    | Price Close High Low ... |
| 307   | å°æ³¥  | 2012-03-30 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | -0.062415          | 0.211845            | 77,511,817,420   | 0.177009             | -0.237003                     | 0.183163                      | -0.647645                    | 0.208716                   | Price Close High Low ... |
| 308   | å°æ³¥  | 2013-05-15 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.218931           | 0.038461            | 77,511,817,420   | -1.796884            | -2.58713                      | -2.33914                      | -1.083479                    | -3.069321                  | Price Close High Low ... |
| 309   | å°æ³¥  | 2013-08-14 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.022766           | 0.053985            | 77,511,817,420   | -0.169579            | -0.745016                     | -1.62934                      | -0.745731                    | -0.956139                  | Price Close High Low ... |
| 313   | å°æ³¥  | 2013-08-14 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.022766           | 0.053985            | 77,511,817,420   | 0.192859             | 0.661097                      | 0.793124                      | 0.802544                     | -0.196808                  | Price Close High Low ... |
| 314   | å°æ³¥  | 2013-11-14 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.059431           | 0.161928            | 77,511,817,420   | 0.987591             | 0.825564                      | 1.283005                      | -0.709972                    | -1.556281                  | Price Close High Low ... |
| 315   | å°æ³¥  | 2014-03-31 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.107185           | -0.042283           | 77,511,817,420   | -0.29677             | -0.76883                      | 0.328945                      | -1.251529                    | -0.902194                  | Price Close High Low ... |
| 316   | å°æ³¥  | 2014-05-15 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | -0.052301          | 0.091589            | 77,511,817,420   | 1.219027             | 1.450653                      | 1.479293                      | 1.943531                     | 0.844266                   | Price Close High Low ... |
| 317   | å°æ³¥  | 2014-08-14 | æ°´æ³¥è£½é€  | æ°´æ³¥è£½é€       | 0.053538           | -0.016393           | 77,511,817,420   | 0.263899             | 0.034964                      | 0.569898                      | -1.079002                    | -0.686497                  | Price Close High       |

### è·‘å›åœˆè¨ˆç®—æ‰€æœ‰ä¸Šå¸‚æ«ƒå…¬å¸é©šå¥‡æŒ‡æ¨™
````python
# è¼‰å…¥è‚¡ç¥¨åç¨±æ¸…å–®
df = pd.read_csv("C:/Users/USER/Downloads/2010è‡³ä»Šeps.csv")
concat_df = pd.DataFrame()

# å°æ‰€æœ‰è‚¡ç¥¨é€²è¡Œåˆ†æ
for stock_name in tqdm(df["åç¨±"], desc="åˆ†æé€²åº¦"):
    try:
        analyzer = SurpriseAnalyzer(stock_name)
        result = analyzer.analyze()
        result["stock"] = stock_name  # åŠ ä¸Šå…¬å¸æ¨™ç±¤
        concat_df = pd.concat([concat_df, result])
    except Exception as e:
        print(f" {stock_name} ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
````
### è®Šæ•¸åˆ†å¸ƒå‹æ…‹
![Variable distribution](distriburion.png)

## ä¸‰ã€ç›¸é—œæ€§æª¢é©—
### 1. ğŸ“‰ Linear Model for Initial Variable Filtering
We first use a simple linear regression model to detect preliminary relationships between surprise indices and stock/sector returns.
````python
# å®šç¾©ç”¨ä¾†çš„ç‰¹å¾µæ¬„ä½
X_cols = [
    "surprised_index_gross_profit",
    "surprised_index_current_ratio",
    "surprised_index_eps",
    "surprised_index_roa_beforetta",
    "surprised_index_operating_cashflow",
]
# å»æ¥µå€¼
cd = trim_outliers_joint(df, X_cols + ["this_season_return"])
cd = cd.dropna()

# X, y
X = cd[X_cols]
y = cd["this_season_return"]

# å»ºç«‹ä¸¦è¨“ç·´æ¨¡å‹
model = LinearRegression()
model.fit(X, y)

# é æ¸¬
y_pred = model.predict(X)
````
![Linear Model Output](output.png)  

-  **é æ¸¬èˆ‡çœŸå¯¦çš„ç›¸é—œä¿‚æ•¸ r = 0.1007, p-value = 8.374e-91**\
  

### 2.å„è®Šæ•¸ç›¸é—œæ€§
![Variables corr](muti_variable.png)  

---

### 3. Industry-Level Correlation Analysis
We examine how different sectors respond to surprise indices.



---

### 4. Feature Importance via Random Forest
We apply Random Forest to further assess variable importance and capture nonlinear relationships.
````python
X_cols = [
    "eps",
    "current_ratio",
    "surprised_index_eps",
    "surprised_index_current_ratio",
    "surprised_index_gross_profit",
    "surprised_index_operating_cashflow",
    "surprised_index_roa_beforetta",
    "industry_dummy"
]

# Step 1: è½‰æ›ç›®æ¨™è®Šæ•¸ç‚ºä¸‰åˆ†é¡ 
# åˆ†æˆï¼šä¸‹è·Œï¼ˆ0ï¼‰ã€æŒå¹³ï¼ˆ1ï¼‰ã€ä¸Šæ¼²ï¼ˆ2ï¼‰
quantiles = df["this_season_return"].quantile([0.33, 0.66]).values
def classify_return(x):
    if x <= quantiles[0]:
        return 0  # ä¸‹è·Œ
    elif x <= quantiles[1]:
        return 1  # æŒå¹³
    else:
        return 2  # ä¸Šæ¼²

df["y_class"] = df["this_season_return"].apply(classify_return)

# Step 2: å»ºç«‹ X å’Œ y
X = df[X_cols]
y = df["y_class"]

df_model = pd.concat([X, y, df["this_season_return"]], axis=1).dropna()
X = df_model[X_cols]
y = df_model["y_class"]

# Step 3: åˆ‡åˆ†è³‡æ–™ 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)

# Step 4å»ºç«‹ä¸¦è¨“ç·´åˆ†é¡æ¨¡å‹
clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=3) #min_sample_leafè¨­3é˜²æ­¢overfitting
clf.fit(X_train, y_train)

````


- **Random Forest results**\
  ![Random Forest Model results](image.png)\
  å¯ä»¥çœ‹åˆ°f-scoreé¡¯è‘—å¤§æ–¼0.33 è¡¨ç¤ºæœ‰ä¸€å®šé æ¸¬èƒ½åŠ›ã€‚
- **Variable Importance**\
  ![Variable Importance](variable_impo.png)\
  èˆ‡ç·šæ€§æ¨¡å‹çµæœä¸€è‡´ï¼Œå¯ä»¥ç¢ºèªç‡Ÿæ”¶æŒ‡æ¨™çš„é æ¸¬èƒ½åŠ›è¼ƒç‚ºä½³ã€‚
  

- **Feature Heatmap**\
  ![Random Forest Heatmap](randomforest_heat.png)\
  é€²ä¸€æ­¥å¾åˆ†é¡ç†±åº¦åœ–å¯ä»¥çœ‹å‡ºï¼Œéš¨æ©Ÿæ£®æ—æ¨¡å‹åœ¨æ•æ‰é æ¸¬å„ªè³ªè‚¡ç¥¨çš„è¡¨ç¾æ¯”ç·šæ€§æ¨¡å‹è¼ƒä½³ã€‚

---

## ä¸‰ã€ç­–ç•¥å»ºæ§‹
### 1. Simple screening
åœ¨é©—è­‰é©šå¥‡æŒ‡æ¨™å°æ–¼å–®å­£å ±é…¬æœ‰é æ¸¬èƒ½åŠ›ä»¥å¾Œï¼Œæˆ‘å€‘å…ˆä½¿ç”¨ä¸åŒé æ¸¬åˆ†æ•¸çš„é–€æª»å€¼ä¾†å‹•æ…‹æ›´æ–°æŠ•è³‡çµ„åˆã€‚\
é€™é‚Šç”¨for loopè·‘éå›æ¸¬æœŸé–“çš„æ¯ä¸€å¤©ï¼Œå¦‚æœç•¶å¤©æœ‰å…¬å¸å…¬å¸ƒè²¡å‹™å ±è¡¨ï¼Œä»¥ä¸‹ç¨‹å¼ç¢¼å°±æœƒç”¨ä»–å°æ‡‰çš„é©šå¥‡æŒ‡æ•¸ä¾†åˆ¤æ–·æ˜¯å¦å°‡å…¶åŠ å…¥æŠ•è³‡çµ„åˆï¼Œæ¯æ¬¡åŠ å…¥ç‚ºæœŸä¸€å­£ã€‚æœ€å¾Œå†ç°¡å–®å¹³å‡ç•¶å¤©æŒæœ‰çš„æ‰€æœ‰è‚¡ç¥¨å ±é…¬ç‡ã€‚
````python
# åˆå§‹åŒ–
returns_80    = pd.Series(dtype='float64')
returns_50abv = pd.Series(dtype='float64')
returns_50blw = pd.Series(dtype='float64')
returns_20    = pd.Series(dtype='float64')

# quantiles
pr80 = np.quantile(y_pred, 0.8)
pr50 = np.quantile(y_pred, 0.5)
pr20 = np.quantile(y_pred, 0.2)

# ä¸‰å€‹æŠ•çµ„çš„è‚¡ç¥¨åˆ—è¡¨
portfolio_80 = np.array([])
portfolio_50abv = np.array([])
portfolio_50blw = np.array([])
portfolio_20 = np.array([])

# è¨ˆç®—æ¯æ—¥æŠ•çµ„å¹³å‡å ±é…¬çš„å‡½æ•¸
def get_return(portfolio, date):
    if date not in return_df.index:
        return np.nan
    # é¿å… portfolio ä¸­æœ‰ä¸å­˜åœ¨çš„è‚¡ç¥¨ä»£ç¢¼
    valid = [s for s in portfolio if s in return_df.columns]
    if not valid:
        return np.nan
    return return_df.loc[date, valid].mean()

# é€æ—¥æ›´æ–°
for i in date:

    today_new = cd.loc[cd["date"] == i].copy()

    # ç§»é™¤ä»Šå¤©å‰›å…¬å‘Šçš„è‚¡ç¥¨
    portfolio_80     = portfolio_80[~np.isin(portfolio_80, today_new["stock"].values)]
    portfolio_50abv  = portfolio_50abv[~np.isin(portfolio_50abv, today_new["stock"].values)]
    portfolio_50blw  = portfolio_50blw[~np.isin(portfolio_50blw, today_new["stock"].values)]
    portfolio_20     = portfolio_20[~np.isin(portfolio_20, today_new["stock"].values)]

    # åˆ†åˆ¥æŒ‘å‡ºä»Šå¤©è¦åŠ å…¥çš„è‚¡ç¥¨
    buy80 = today_new["return_pred"] >= pr80
    buy50abv = today_new["return_pred"] >= pr50
    buy50blw = today_new["return_pred"] <= pr50
    buy20 = today_new["return_pred"] <= pr20


     # åˆ†åˆ¥åŠ å…¥æ–°çš„è‚¡ç¥¨
    portfolio_80     = np.concatenate([portfolio_80, today_new.loc[buy80, "stock"].values])
    portfolio_50abv  = np.concatenate([portfolio_50abv, today_new.loc[buy50abv, "stock"].values])
    portfolio_50blw  = np.concatenate([portfolio_50blw, today_new.loc[buy50blw, "stock"].values])
    portfolio_20     = np.concatenate([portfolio_20, today_new.loc[buy20, "stock"].values])

    # è¨ˆç®—ä¸‰çµ„æŠ•çµ„çš„å›å ±
    returns_80.loc[i] = get_return(portfolio_80, i)
    returns_50abv.loc[i] = get_return(portfolio_50abv, i)
    returns_50blw.loc[i] = get_return(portfolio_50blw, i)
    returns_20.loc[i] = get_return(portfolio_20, i)
````
- **Screening Strategy Performance**\
  ![Screening Performance](screening_performance.png)

- **Return Comparison**\
  ![Return Comparison](return_compare.png)

- **Sharpe Ratio Comparison**\
  ![Sharpe Comparison](sharp_compare.png)

---

## 2. Final Strategy: Long-Short Top/Bottom 20%

We select the **top 20%** and **bottom 20%** ranked stocks to build a **market-neutral long-short strategy** in both periods.

- #### step 1.
We split the timeline into training and testing periods to ensure robustness:

    - **Training period**: 2011â€“2021/10  
    - **Testing period**: 2021/11â€“2025/01
  
    - ç”¨training period è³‡æ–™é‡æ–°è¨“ç·´:
````python
cd_train = cd.loc[cd["date"]<"2022-01"] #è¨“ç·´è³‡æ–™ 2011~2021/10

# X, y
x = cd_train[X_cols]
y = cd_train["this_season_return"]

# å»ºç«‹ä¸¦è¨“ç·´æ¨¡å‹
model = LinearRegression()
model.fit(x, y)

X2 = cd[X_cols]
# é æ¸¬
y_pred = model.predict(X2)
cd["return_pred"] = y_pred
````



- #### step 2.
å›æ¸¬ç­–ç•¥ (åƒè€ƒ3-1çš„ç¨‹å¼ç¢¼)

- **Final Strategy Backtest**\
  ![Strategy Performance](strat_perform.png)

---
- Maximum drawdown 

![Drawdown](drawdown.png)

---

#### ğŸ“ˆ Final Strategy Backtest (Train vs. Test)

| Metric                | Train (2011â€“2021/10) | Test (2021/11â€“2025/01) |
|------------------------|----------------------|-------------------------|
| Annualized Return      | 0.0938               | 0.1699                  |
| Annualized Volatility  | 0.0580               | 0.0694                  |
| Sharpe Ratio           | 1.5733               | 2.2957                  |
| Cumulative Return      | 0.2950               | 4.5512                  |

---

## â–¶ï¸ Run This Project

```bash
git clone https://github.com/your_username/suprise-index-investment-strategy.git
cd suprise-index-investment-strategy
jupyter notebook strategy_pipeline.ipynb
